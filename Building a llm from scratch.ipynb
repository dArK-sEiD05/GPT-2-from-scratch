{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RQ43Oguyak1n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "file_path=\"the-verdict.txt\"\n",
        "url=\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "  with urllib.request.urlopen(url) as response:\n",
        "    text_data=response.read().decode('utf-8')\n",
        "  with open(file_path,'w',encoding=\"utf-8\") as f:\n",
        "    f.write(text_data)\n",
        "else:\n",
        "  with open(file_path,\"r\",encoding=\"utf-8\") as rf:\n",
        "    text_data=rf.read()\n",
        "\n",
        "raw_text=text_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text=\"Hello, world.\"\n",
        "text=re.split(r\"(\\s)\",text)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdMrG21YU4Qd",
        "outputId": "bc2c9717-f53e-4e12-80c8-fbe03bd60dc9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello,', ' ', 'world.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Hello, world.\"\n",
        "text=re.split(r\"([,.]|\\s)\",text)\n",
        "text\n",
        "#Empty strings are due to matched delimiter space and , coming together"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAbDwkGiaJd4",
        "outputId": "b8a5a3fa-0ad7-46bb-c57f-ef7600cce77f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', ',', '', ' ', 'world', '.', '']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=[item for item in text if item.strip()]\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG4qbMQzcFYU",
        "outputId": "bf72126d-4903-415d-ecbb-fd288e368c75"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', ',', 'world', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Hello, world.\"\n",
        "text = re.split(r'([,.:;$?/!\"()\\-_\\']|--|\\s)',text)\n",
        "result=[i for i in text if i.strip()]\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzmohuLSev-a",
        "outputId": "c1dbf9cb-11bd-4ca4-a082-5a181b2a779b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', ',', 'world', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HiNTQ5PofPKI",
        "outputId": "5f569903-a8ac-4b75-abcb-3c9370d3fa9f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I HAD alwa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed=re.split(r'([,.:;$?/!\"()\\_\\']|--|\\s)',raw_text)\n",
        "result=[text for text in preprocessed if text.strip()]\n",
        "result[:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSbBPjCUfg86",
        "outputId": "eb4a3542-024d-4bec-cd10-8d8a17f85e20"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'HAD',\n",
              " 'always',\n",
              " 'thought',\n",
              " 'Jack',\n",
              " 'Gisburn',\n",
              " 'rather',\n",
              " 'a',\n",
              " 'cheap',\n",
              " 'genius',\n",
              " '--',\n",
              " 'though',\n",
              " 'a',\n",
              " 'good',\n",
              " 'fellow',\n",
              " 'enough',\n",
              " '--',\n",
              " 'so',\n",
              " 'it',\n",
              " 'was',\n",
              " 'no',\n",
              " 'great',\n",
              " 'surprise',\n",
              " 'to',\n",
              " 'me',\n",
              " 'to',\n",
              " 'hear',\n",
              " 'that',\n",
              " ',',\n",
              " 'in']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Next we have to assign token ids\n",
        "each text in dataset is considered as vocabulary and is assigned unique token id\n",
        "vocabulary has a list of all words in sorted order\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Jq4vNNHxfqqN",
        "outputId": "4b4965b3-7fae-48b8-fc00-f07e4540ba30"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Next we have to assign token ids\\neach text in dataset is considered as vocabulary and is assigned unique token id\\nvocabulary has a list of all words in sorted order\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=sorted(set(result))\n",
        "vocab={token:integer for integer,token in enumerate(result)}\n",
        "vocab_size=len(vocab)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PHjxaHeXgUn5",
        "outputId": "4568f2cd-8d6d-47e8-8c6c-1876c42bc027"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1130"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qo56Zya_hD30"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimplifiedTokenizerV1:\n",
        "  def __init__(self,vocab):\n",
        "    self.str_to_int=vocab\n",
        "    self.int_to_str={i:s for s,i in vocab.items()}\n",
        "  def encode(self,text):\n",
        "    preprocessed=re.split(r'([,.:;$?/!\"()\\_\\']|--|\\s)',text)\n",
        "    preprocessed=[text.strip() for text in preprocessed if text.strip()]\n",
        "    ids=[self.str_to_int[s] for s in preprocessed ]\n",
        "    return ids\n",
        "\n",
        "  def decode(self,ids):\n",
        "    text=[self.int_to_str[id] for id in ids]\n",
        "    text=\" \".join(text)\n",
        "    text=re.sub(r'(\\s)+([,.()?/!\\'\\\"])',r'\\2',text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "5cezZNn4g4Bd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=SimplifiedTokenizerV1(vocab)\n",
        "text=\"I always thought, he was a genius?\"\n",
        "ids=tokenizer.encode(text)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCEstICcqgGg",
        "outputId": "8b85f0f1-1b06-4f7d-e677-00e332e35568"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[53, 149, 1003, 5, 533, 1077, 115, 486, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JrmYV9Bus725",
        "outputId": "702efd38-c170-4c15-f857-e67b3e8dcb81"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I always thought, he was a genius?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#special context tokens for handling unkown words and end of text\n",
        "#end of text is to tell model that a text has ended so that model knows the data is segregated and colleceted from different sources\n",
        "\n"
      ],
      "metadata": {
        "id": "48IwEmwjtGLn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens=sorted((set(result)))\n",
        "all_tokens.extend([\"<|endoftext|>\",\"<|unk|>\"])\n",
        "vocab={token:integer for integer,token in enumerate(all_tokens)}\n",
        "vocab_size=len(vocab)\n",
        "vocab_size\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LDsZFv6z0Sfo",
        "outputId": "8bf4fda4-b346-4172-b750-12869a704835"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1132"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimplifiedTokenizerV2:\n",
        "  def __init__(self,vocab):\n",
        "    self.str_to_int=vocab\n",
        "    self.int_to_str={i:s for s,i in vocab.items()}\n",
        "  def encode(self,text):\n",
        "    preprocessed=re.split(r'([,.:;$?/!\"()\\_\\']|--|\\s)',text)\n",
        "    preprocessed=[text.strip() for text in preprocessed if text.strip()]\n",
        "    preprocessed=[item if(item in self.str_to_int)\n",
        "    else \"<|unk|>\" for item in preprocessed]\n",
        "    ids=[self.str_to_int[s] for s in preprocessed ]\n",
        "    return ids\n",
        "\n",
        "  def decode(self,ids):\n",
        "    text=[self.int_to_str[id] for id in ids]\n",
        "    text=\" \".join(text)\n",
        "    text=re.sub(r'(\\s)+([,.()?/!\\'\\\"])',r'\\2',text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "h3yCQooV1SNe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=SimplifiedTokenizerV2(vocab)\n",
        "text=\"I always thought, he was a gens?\"\n",
        "text2=\"In the sunlit\"\n",
        "joined=\" <|endoftext|> \".join((text,text2))\n",
        "ids=tokenizer.encode(joined)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9MWGfoe1OKY",
        "outputId": "d57127f0-f755-40f5-a5a3-eba751d38920"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[53, 149, 1003, 5, 533, 1077, 115, 1131, 10, 1130, 55, 988, 956]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "[PAD] -Padding tokken to match batch size\n",
        "[BOS] -begging of a sentence\n",
        "[EOS] -end of a sentence\n",
        "[UNK] -unknown token\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TGxd1WxE3s_5",
        "outputId": "d8bcb6b8-49ed-425d-e282-fe87f568e3b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n[PAD] -Padding tokken to match batch size\\n[BOS] -begging of a sentence\\n[EOS] -end of a sentence\\n[UNK] -unknown token\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MUeH05Pc3AQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FshNPcqH2Uyu",
        "outputId": "ff825060-53ee-48f5-8948-4e9cb3fe8733"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I always thought, he was a <|unk|>? <|endoftext|> In the sunlit'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BPE\n"
      ],
      "metadata": {
        "id": "Pshrxd3lgdwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGpqwf1V716j",
        "outputId": "567aac12-321f-4524-fa1a-3ebdcc1d74a4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "tokenizer=tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "m01jmoMOGzua"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Hello do you like tea? <|endoftext|> In the sunlit he was a genius of a someunkownplace. someunknown\"\n",
        "ids=tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmyRLQ9LZ1C-",
        "outputId": "ee889a20-fa33-4930-f67f-4318b1aa1d4e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15496,\n",
              " 466,\n",
              " 345,\n",
              " 588,\n",
              " 8887,\n",
              " 30,\n",
              " 220,\n",
              " 50256,\n",
              " 554,\n",
              " 262,\n",
              " 4252,\n",
              " 18250,\n",
              " 339,\n",
              " 373,\n",
              " 257,\n",
              " 15632,\n",
              " 286,\n",
              " 257,\n",
              " 617,\n",
              " 2954,\n",
              " 593,\n",
              " 5372,\n",
              " 13,\n",
              " 617,\n",
              " 34680]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenized_data=tokenizer.encode(raw_text)\n",
        "total_len=len(tokenized_data)\n",
        "tokenized_data"
      ],
      "metadata": {
        "id": "Tm0YT5MSZcSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "71d94826-b86d-4a5f-a3c7-c13cdaf09e1a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40,\n",
              " 367,\n",
              " 2885,\n",
              " 1464,\n",
              " 1807,\n",
              " 3619,\n",
              " 402,\n",
              " 271,\n",
              " 10899,\n",
              " 2138,\n",
              " 257,\n",
              " 7026,\n",
              " 15632,\n",
              " 438,\n",
              " 2016,\n",
              " 257,\n",
              " 922,\n",
              " 5891,\n",
              " 1576,\n",
              " 438,\n",
              " 568,\n",
              " 340,\n",
              " 373,\n",
              " 645,\n",
              " 1049,\n",
              " 5975,\n",
              " 284,\n",
              " 502,\n",
              " 284,\n",
              " 3285,\n",
              " 326,\n",
              " 11,\n",
              " 287,\n",
              " 262,\n",
              " 6001,\n",
              " 286,\n",
              " 465,\n",
              " 13476,\n",
              " 11,\n",
              " 339,\n",
              " 550,\n",
              " 5710,\n",
              " 465,\n",
              " 12036,\n",
              " 11,\n",
              " 6405,\n",
              " 257,\n",
              " 5527,\n",
              " 27075,\n",
              " 11,\n",
              " 290,\n",
              " 4920,\n",
              " 2241,\n",
              " 287,\n",
              " 257,\n",
              " 4489,\n",
              " 64,\n",
              " 319,\n",
              " 262,\n",
              " 34686,\n",
              " 41976,\n",
              " 13,\n",
              " 357,\n",
              " 10915,\n",
              " 314,\n",
              " 2138,\n",
              " 1807,\n",
              " 340,\n",
              " 561,\n",
              " 423,\n",
              " 587,\n",
              " 10598,\n",
              " 393,\n",
              " 28537,\n",
              " 2014,\n",
              " 198,\n",
              " 198,\n",
              " 1,\n",
              " 464,\n",
              " 6001,\n",
              " 286,\n",
              " 465,\n",
              " 13476,\n",
              " 1,\n",
              " 438,\n",
              " 5562,\n",
              " 373,\n",
              " 644,\n",
              " 262,\n",
              " 1466,\n",
              " 1444,\n",
              " 340,\n",
              " 13,\n",
              " 314,\n",
              " 460,\n",
              " 3285,\n",
              " 9074,\n",
              " 13,\n",
              " 46606,\n",
              " 536,\n",
              " 5469,\n",
              " 438,\n",
              " 14363,\n",
              " 938,\n",
              " 4842,\n",
              " 1650,\n",
              " 353,\n",
              " 438,\n",
              " 2934,\n",
              " 489,\n",
              " 3255,\n",
              " 465,\n",
              " 48422,\n",
              " 540,\n",
              " 450,\n",
              " 67,\n",
              " 3299,\n",
              " 13,\n",
              " 366,\n",
              " 5189,\n",
              " 1781,\n",
              " 340,\n",
              " 338,\n",
              " 1016,\n",
              " 284,\n",
              " 3758,\n",
              " 262,\n",
              " 1988,\n",
              " 286,\n",
              " 616,\n",
              " 4286,\n",
              " 705,\n",
              " 1014,\n",
              " 510,\n",
              " 26,\n",
              " 475,\n",
              " 314,\n",
              " 836,\n",
              " 470,\n",
              " 892,\n",
              " 286,\n",
              " 326,\n",
              " 11,\n",
              " 1770,\n",
              " 13,\n",
              " 8759,\n",
              " 2763,\n",
              " 438,\n",
              " 1169,\n",
              " 2994,\n",
              " 284,\n",
              " 943,\n",
              " 17034,\n",
              " 318,\n",
              " 477,\n",
              " 314,\n",
              " 892,\n",
              " 286,\n",
              " 526,\n",
              " 383,\n",
              " 1573,\n",
              " 11,\n",
              " 319,\n",
              " 9074,\n",
              " 13,\n",
              " 536,\n",
              " 5469,\n",
              " 338,\n",
              " 11914,\n",
              " 11,\n",
              " 33096,\n",
              " 663,\n",
              " 4808,\n",
              " 3808,\n",
              " 62,\n",
              " 355,\n",
              " 996,\n",
              " 484,\n",
              " 547,\n",
              " 12548,\n",
              " 287,\n",
              " 281,\n",
              " 13079,\n",
              " 410,\n",
              " 12523,\n",
              " 286,\n",
              " 22353,\n",
              " 13,\n",
              " 843,\n",
              " 340,\n",
              " 373,\n",
              " 407,\n",
              " 691,\n",
              " 262,\n",
              " 9074,\n",
              " 13,\n",
              " 536,\n",
              " 48819,\n",
              " 508,\n",
              " 25722,\n",
              " 276,\n",
              " 13,\n",
              " 11161,\n",
              " 407,\n",
              " 262,\n",
              " 40123,\n",
              " 18113,\n",
              " 544,\n",
              " 9325,\n",
              " 701,\n",
              " 11,\n",
              " 379,\n",
              " 262,\n",
              " 938,\n",
              " 402,\n",
              " 1617,\n",
              " 261,\n",
              " 12917,\n",
              " 905,\n",
              " 11,\n",
              " 5025,\n",
              " 502,\n",
              " 878,\n",
              " 402,\n",
              " 271,\n",
              " 10899,\n",
              " 338,\n",
              " 366,\n",
              " 31640,\n",
              " 12,\n",
              " 67,\n",
              " 20811,\n",
              " 1,\n",
              " 284,\n",
              " 910,\n",
              " 11,\n",
              " 351,\n",
              " 10953,\n",
              " 287,\n",
              " 607,\n",
              " 2951,\n",
              " 25,\n",
              " 366,\n",
              " 1135,\n",
              " 2236,\n",
              " 407,\n",
              " 804,\n",
              " 2402,\n",
              " 663,\n",
              " 588,\n",
              " 757,\n",
              " 13984,\n",
              " 198,\n",
              " 198,\n",
              " 5779,\n",
              " 28112,\n",
              " 10197,\n",
              " 832,\n",
              " 262,\n",
              " 46475,\n",
              " 286,\n",
              " 18113,\n",
              " 544,\n",
              " 338,\n",
              " 10953,\n",
              " 314,\n",
              " 2936,\n",
              " 1498,\n",
              " 284,\n",
              " 1986,\n",
              " 262,\n",
              " 1109,\n",
              " 351,\n",
              " 1602,\n",
              " 11227,\n",
              " 414,\n",
              " 13,\n",
              " 23676,\n",
              " 3619,\n",
              " 402,\n",
              " 271,\n",
              " 10899,\n",
              " 0,\n",
              " 383,\n",
              " 1466,\n",
              " 550,\n",
              " 925,\n",
              " 683,\n",
              " 438,\n",
              " 270,\n",
              " 373,\n",
              " 15830,\n",
              " 326,\n",
              " 484,\n",
              " 815,\n",
              " 25722,\n",
              " 683,\n",
              " 13,\n",
              " 9754,\n",
              " 465,\n",
              " 898,\n",
              " 1714,\n",
              " 7380,\n",
              " 30090,\n",
              " 547,\n",
              " 2982,\n",
              " 11,\n",
              " 290,\n",
              " 287,\n",
              " 465,\n",
              " 898,\n",
              " 3292,\n",
              " 8941,\n",
              " 257,\n",
              " 4636,\n",
              " 28582,\n",
              " 13,\n",
              " 18612,\n",
              " 35394,\n",
              " 30,\n",
              " 8673,\n",
              " 13,\n",
              " 1002,\n",
              " 340,\n",
              " 547,\n",
              " 11,\n",
              " 262,\n",
              " 15393,\n",
              " 286,\n",
              " 262,\n",
              " 5977,\n",
              " 373,\n",
              " 29178,\n",
              " 3474,\n",
              " 416,\n",
              " 1310,\n",
              " 40559,\n",
              " 11959,\n",
              " 1636,\n",
              " 11,\n",
              " 508,\n",
              " 11,\n",
              " 287,\n",
              " 477,\n",
              " 922,\n",
              " 4562,\n",
              " 11,\n",
              " 3181,\n",
              " 503,\n",
              " 287,\n",
              " 262,\n",
              " 37090,\n",
              " 257,\n",
              " 845,\n",
              " 22665,\n",
              " 366,\n",
              " 672,\n",
              " 270,\n",
              " 2838,\n",
              " 1,\n",
              " 319,\n",
              " 3619,\n",
              " 438,\n",
              " 505,\n",
              " 286,\n",
              " 883,\n",
              " 905,\n",
              " 88,\n",
              " 6685,\n",
              " 42070,\n",
              " 351,\n",
              " 4738,\n",
              " 6276,\n",
              " 871,\n",
              " 326,\n",
              " 314,\n",
              " 423,\n",
              " 2982,\n",
              " 357,\n",
              " 40,\n",
              " 1839,\n",
              " 470,\n",
              " 910,\n",
              " 416,\n",
              " 4150,\n",
              " 8,\n",
              " 3688,\n",
              " 284,\n",
              " 402,\n",
              " 271,\n",
              " 10899,\n",
              " 338,\n",
              " 12036,\n",
              " 13,\n",
              " 843,\n",
              " 523,\n",
              " 438,\n",
              " 14363,\n",
              " 10568,\n",
              " 852,\n",
              " 5729,\n",
              " 11331,\n",
              " 18893,\n",
              " 540,\n",
              " 438,\n",
              " 1169,\n",
              " 5114,\n",
              " 11835,\n",
              " 3724,\n",
              " 503,\n",
              " 11,\n",
              " 290,\n",
              " 11,\n",
              " 355,\n",
              " 9074,\n",
              " 13,\n",
              " 536,\n",
              " 5469,\n",
              " 550,\n",
              " 11001,\n",
              " 11,\n",
              " 262,\n",
              " 2756,\n",
              " 286,\n",
              " 366,\n",
              " 38,\n",
              " 271,\n",
              " 10899,\n",
              " 82,\n",
              " 1,\n",
              " 1816,\n",
              " 510,\n",
              " 13,\n",
              " 198,\n",
              " 198,\n",
              " 1026,\n",
              " 373,\n",
              " 407,\n",
              " 10597,\n",
              " 1115,\n",
              " 812,\n",
              " 1568,\n",
              " 326,\n",
              " 11,\n",
              " 287,\n",
              " 262,\n",
              " 1781,\n",
              " 286,\n",
              " 257,\n",
              " 1178,\n",
              " 2745,\n",
              " 6,\n",
              " 4686,\n",
              " 1359,\n",
              " 319,\n",
              " 262,\n",
              " 34686,\n",
              " 41976,\n",
              " 11,\n",
              " 340,\n",
              " 6451,\n",
              " 5091,\n",
              " 284,\n",
              " 502,\n",
              " 284,\n",
              " 4240,\n",
              " 1521,\n",
              " 402,\n",
              " 271,\n",
              " 10899,\n",
              " 550,\n",
              " 1813,\n",
              " 510,\n",
              " 465,\n",
              " 12036,\n",
              " 13,\n",
              " 1550,\n",
              " 14580,\n",
              " 11,\n",
              " 340,\n",
              " 1107,\n",
              " 373,\n",
              " 257,\n",
              " 29850,\n",
              " 1917,\n",
              " 13,\n",
              " 1675,\n",
              " 24456,\n",
              " 465,\n",
              " 3656,\n",
              " 561,\n",
              " 423,\n",
              " 587,\n",
              " 1165,\n",
              " 2562,\n",
              " 438,\n",
              " 14363,\n",
              " 3148,\n",
              " 1650,\n",
              " 1010,\n",
              " 550,\n",
              " 587,\n",
              " 6699,\n",
              " 262,\n",
              " 1540,\n",
              " 558,\n",
              " 286,\n",
              " 2282,\n",
              " 326,\n",
              " 9074,\n",
              " 13,\n",
              " 402,\n",
              " 271,\n",
              " 10899,\n",
              " 550,\n",
              " 366,\n",
              " 7109,\n",
              " 14655,\n",
              " 683,\n",
              " 866,\n",
              " 526,\n",
              " 1114,\n",
              " 9074,\n",
              " 13,\n",
              " 402,\n",
              " 271,\n",
              " 10899,\n",
              " 438,\n",
              " 292,\n",
              " 884,\n",
              " 438,\n",
              " 18108,\n",
              " 407,\n",
              " 11196,\n",
              " 10597,\n",
              " 3016,\n",
              " 257,\n",
              " 614,\n",
              " 706,\n",
              " 3619,\n",
              " 338,\n",
              " 10568,\n",
              " 550,\n",
              " 587,\n",
              " 2077,\n",
              " 13,\n",
              " 632,\n",
              " 1244,\n",
              " 307,\n",
              " 326,\n",
              " 339,\n",
              " 550,\n",
              " 6405,\n",
              " 607,\n",
              " 438,\n",
              " 20777,\n",
              " 339,\n",
              " 8288,\n",
              " 465,\n",
              " 10152,\n",
              " 438,\n",
              " 13893,\n",
              " 339,\n",
              " 1422,\n",
              " 470,\n",
              " 765,\n",
              " 284,\n",
              " 467,\n",
              " 319,\n",
              " 12036,\n",
              " 26,\n",
              " 475,\n",
              " 340,\n",
              " 561,\n",
              " 423,\n",
              " 587,\n",
              " 1327,\n",
              " 284,\n",
              " 5879,\n",
              " 326,\n",
              " 339,\n",
              " 550,\n",
              " 1813,\n",
              " 510,\n",
              " 465,\n",
              " 12036,\n",
              " 780,\n",
              " 339,\n",
              " 550,\n",
              " 6405,\n",
              " 607,\n",
              " 13,\n",
              " 198,\n",
              " 198,\n",
              " 5189,\n",
              " 1781,\n",
              " 11,\n",
              " 611,\n",
              " 673,\n",
              " 550,\n",
              " 407,\n",
              " 17901,\n",
              " 683,\n",
              " 866,\n",
              " 11,\n",
              " 673,\n",
              " 550,\n",
              " 8603,\n",
              " 11,\n",
              " 355,\n",
              " 4544,\n",
              " 9325,\n",
              " 701,\n",
              " 42397,\n",
              " 11,\n",
              " 4054,\n",
              " 284,\n",
              " 366,\n",
              " 26282,\n",
              " 683,\n",
              " 510,\n",
              " 1,\n",
              " 438,\n",
              " 7091,\n",
              " 550,\n",
              " 407,\n",
              " 2957,\n",
              " 683,\n",
              " 736,\n",
              " 284,\n",
              " 262,\n",
              " 1396,\n",
              " 417,\n",
              " 13,\n",
              " 1675,\n",
              " 1234,\n",
              " 262,\n",
              " 14093,\n",
              " 656,\n",
              " 465,\n",
              " 1021,\n",
              " 757,\n",
              " 438,\n",
              " 10919,\n",
              " 257,\n",
              " 410,\n",
              " 5040,\n",
              " 329,\n",
              " 257,\n",
              " 3656,\n",
              " 0,\n",
              " 887,\n",
              " 9074,\n",
              " 13,\n",
              " 402,\n",
              " 271,\n",
              " 10899,\n",
              " 4120,\n",
              " 284,\n",
              " 423,\n",
              " 595,\n",
              " 67,\n",
              " 1328,\n",
              " 340,\n",
              " 438,\n",
              " 392,\n",
              " 314,\n",
              " 2936,\n",
              " 340,\n",
              " 1244,\n",
              " 307,\n",
              " 3499,\n",
              " 284,\n",
              " 1064,\n",
              " 503,\n",
              " 1521,\n",
              " 13,\n",
              " 198,\n",
              " 198,\n",
              " 464,\n",
              " 748,\n",
              " 586,\n",
              " 652,\n",
              " 1204,\n",
              " 286,\n",
              " 262,\n",
              " 34686,\n",
              " 41976,\n",
              " 37733,\n",
              " 2346,\n",
              " 284,\n",
              " 884,\n",
              " 14177,\n",
              " 8233,\n",
              " 1020,\n",
              " 5768,\n",
              " 26,\n",
              " 290,\n",
              " 1719,\n",
              " 11,\n",
              " 319,\n",
              " 616,\n",
              " 835,\n",
              " 284,\n",
              " 22489,\n",
              " 40089,\n",
              " 11,\n",
              " 4978,\n",
              " 257,\n",
              " 19350,\n",
              " 286,\n",
              " 3619,\n",
              " 338,\n",
              " 3652,\n",
              " 436,\n",
              " 81,\n",
              " 5286,\n",
              " 8812,\n",
              " 2114,\n",
              " 1022,\n",
              " 262,\n",
              " 279,\n",
              " 1127,\n",
              " 11,\n",
              " 314,\n",
              " 550,\n",
              " 3589,\n",
              " 28068,\n",
              " 294,\n",
              " 1555,\n",
              " 262,\n",
              " 1306,\n",
              " 1110,\n",
              " 13,\n",
              " 198,\n",
              " 198,\n",
              " 40,\n",
              " 1043,\n",
              " 262,\n",
              " 3155,\n",
              " 379,\n",
              " 8887,\n",
              " 11061,\n",
              " 511,\n",
              " 18057,\n",
              " 12,\n",
              " 83,\n",
              " 6037,\n",
              " 26,\n",
              " 290,\n",
              " 9074,\n",
              " 13,\n",
              " 402,\n",
              " 271,\n",
              " 10899,\n",
              " 338,\n",
              " 7062,\n",
              " 373,\n",
              " 523,\n",
              " 2429,\n",
              " 498,\n",
              " 326,\n",
              " 11,\n",
              " 287,\n",
              " 262,\n",
              " 29543,\n",
              " 2745,\n",
              " 11,\n",
              " 314,\n",
              " 4752,\n",
              " 340,\n",
              " 6777,\n",
              " 13,\n",
              " 632,\n",
              " 373,\n",
              " 407,\n",
              " 326,\n",
              " 616,\n",
              " 2583,\n",
              " 408,\n",
              " 373,\n",
              " 366,\n",
              " 47914,\n",
              " 1298,\n",
              " 319,\n",
              " 326,\n",
              " 966,\n",
              " 314,\n",
              " 714,\n",
              " 423,\n",
              " 1813,\n",
              " 4544,\n",
              " 9325,\n",
              " 701,\n",
              " 262,\n",
              " 40830,\n",
              " 12719,\n",
              " 3874,\n",
              " 13,\n",
              " 632,\n",
              " 373,\n",
              " 655,\n",
              " 780,\n",
              " 673,\n",
              " 373,\n",
              " 4808,\n",
              " 1662,\n",
              " 62,\n",
              " 3499,\n",
              " 438,\n",
              " 361,\n",
              " 314,\n",
              " 743,\n",
              " 307,\n",
              " 41746,\n",
              " 12004,\n",
              " 262,\n",
              " 6473,\n",
              " 438,\n",
              " 5562,\n",
              " 314,\n",
              " 1043,\n",
              " 607,\n",
              " 523,\n",
              " 13,\n",
              " 1114,\n",
              " 3619,\n",
              " 11,\n",
              " 477,\n",
              " 465,\n",
              " 1204,\n",
              " 11,\n",
              " 550,\n",
              " 587,\n",
              " 11191,\n",
              " 416,\n",
              " 3499,\n",
              " 1466,\n",
              " 25,\n",
              " 484,\n",
              " 550,\n",
              " 26546,\n",
              " 1068,\n",
              " 465,\n",
              " 1242,\n",
              " 11,\n",
              " 340,\n",
              " 550,\n",
              " 587,\n",
              " 302,\n",
              " 1144,\n",
              " 287,\n",
              " 262,\n",
              " 3024,\n",
              " 12,\n",
              " 4803,\n",
              " 286,\n",
              " 511,\n",
              " 512,\n",
              " 1741,\n",
              " 13,\n",
              " 843,\n",
              " 340,\n",
              " 373,\n",
              " 4361,\n",
              " 5048,\n",
              " 425,\n",
              " 284,\n",
              " 3465,\n",
              " 644,\n",
              " 1245,\n",
              " 262,\n",
              " 366,\n",
              " 25124,\n",
              " 3101,\n",
              " 8137,\n",
              " 286,\n",
              " 16957,\n",
              " 1696,\n",
              " 414,\n",
              " 1,\n",
              " 357,\n",
              " 40,\n",
              " 9577,\n",
              " 4544,\n",
              " 9325,\n",
              " 701,\n",
              " 8,\n",
              " 373,\n",
              " 1719,\n",
              " 319,\n",
              " 683,\n",
              " 13,\n",
              " 198,\n",
              " 198,\n",
              " 40,\n",
              " 423,\n",
              " 4750,\n",
              " 326,\n",
              " 9074,\n",
              " 13,\n",
              " 402,\n",
              " 271,\n",
              " 10899,\n",
              " 373,\n",
              " 5527,\n",
              " 26,\n",
              " 290,\n",
              " 340,\n",
              " 373,\n",
              " 3393,\n",
              " 34953,\n",
              " 856,\n",
              " 326,\n",
              " 607,\n",
              " 5229,\n",
              " 373,\n",
              " 37895,\n",
              " 422,\n",
              " 428,\n",
              " 25179,\n",
              " 257,\n",
              " 19217,\n",
              " 475,\n",
              " 8904,\n",
              " 14676,\n",
              " 13,\n",
              " 632,\n",
              " 318,\n",
              " 11,\n",
              " 355,\n",
              " 257,\n",
              " 3896,\n",
              " 11,\n",
              " 262,\n",
              " 661,\n",
              " 508,\n",
              " 40987,\n",
              " 1637,\n",
              " 508,\n",
              " 651,\n",
              " 749,\n",
              " 503,\n",
              " 286,\n",
              " 340,\n",
              " 26,\n",
              " 290,\n",
              " 3619,\n",
              " 338,\n",
              " 19992,\n",
              " 31564,\n",
              " 286,\n",
              " 465,\n",
              " 3656,\n",
              " 338,\n",
              " 1263,\n",
              " 5236,\n",
              " 9343,\n",
              " 683,\n",
              " 11,\n",
              " 351,\n",
              " 281,\n",
              " 5585,\n",
              " 286,\n",
              " 2818,\n",
              " 922,\n",
              " 12,\n",
              " 49705,\n",
              " 11,\n",
              " 284,\n",
              " 21595,\n",
              " 1133,\n",
              " 340,\n",
              " 656,\n",
              " 5563,\n",
              " 286,\n",
              " 1242,\n",
              " 290,\n",
              " 13064,\n",
              " 13,\n",
              " 1675,\n",
              " 262,\n",
              " 6846,\n",
              " 11,\n",
              " 314,\n",
              " 1276,\n",
              " 751,\n",
              " 11,\n",
              " 339,\n",
              " 6150,\n",
              " 5365,\n",
              " 31655,\n",
              " 26,\n",
              " 475,\n",
              " 339,\n",
              " 373,\n",
              " 7067,\n",
              " 29396,\n",
              " 18443,\n",
              " 12271,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_size=4\n",
        "x=[]\n",
        "y=[]\n",
        "stride=1\n",
        "for i in range(0,total_len-context_size,stride):\n",
        "  x.append(tokenized_data[i:i+context_size])\n",
        "  y.append(tokenized_data[i+1:i+1+context_size])\n"
      ],
      "metadata": {
        "id": "szWIfDFuafOB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0],y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyMO46spa5dC",
        "outputId": "83cbb351-a93f-43ff-a26d-63613b250a54"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([40, 367, 2885, 1464], [367, 2885, 1464, 1807])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torch"
      ],
      "metadata": {
        "id": "ILxquU6-a1II"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDataset(Dataset):\n",
        "  def __init__(self,txt,encode,tokenizer,max_length,stride):\n",
        "    self.input_data=[]\n",
        "    self.output_data=[]\n",
        "    token_ids=tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
        "    for i in range(0,len(token_ids)-max_length,stride):\n",
        "      self.input_data.append(torch.tensor(token_ids[i:i+max_length]))\n",
        "      self.output_data.append(torch.tensor(token_ids[i+1:i+1+max_length]))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_data)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_data[idx],self.output_data[idx]\n"
      ],
      "metadata": {
        "id": "13uJUKrgbQxi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(txt,batch_size=2,max_length=256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
        "  tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset=GPTDataset(txt,tokenizer.encode,tokenizer,max_length,stride)\n",
        "  dataloader=DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last,num_workers=num_workers)\n",
        "  return dataloader\n"
      ],
      "metadata": {
        "id": "9UyZ5NBZcYZ6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader(\n",
        "    raw_text, batch_size=5, max_length=4, stride=1, shuffle=False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZpYkqNHT21l",
        "outputId": "8f011a4d-f1a5-4094-d8c5-c81ac29ec30e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40,  367, 2885, 1464],\n",
            "        [ 367, 2885, 1464, 1807],\n",
            "        [2885, 1464, 1807, 3619],\n",
            "        [1464, 1807, 3619,  402],\n",
            "        [1807, 3619,  402,  271]]), tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 2885,  1464,  1807,  3619],\n",
            "        [ 1464,  1807,  3619,   402],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [ 3619,   402,   271, 10899]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch import tensor\n"
      ],
      "metadata": {
        "id": "gkX7n-2VH8l2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=tensor([1])\n",
        "y=tensor([2])\n",
        "x@y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwzC4ALZHsi8",
        "outputId": "c77613b5-49a2-4bad-b764-4b59679f96f8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FzzWBHtpbGXn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector=tensor(\n",
        "    [[0.43,0.15,0.89],\n",
        "   [0.55,0.87,0.66],\n",
        "    [0.57,0.85,0.64],\n",
        "     [0.22,0.58,0.33],\n",
        "    [0.77,0.25,0.10],\n",
        "    [0.05,0.80,0.55]]\n",
        "  )"
      ],
      "metadata": {
        "id": "k4YKIyMfZEIi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_embeddings={}\n",
        "for i,v in enumerate(vector):\n",
        "  vector_embeddings[i]=v\n",
        "vector_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6O9yhwATqZF",
        "outputId": "97bda88e-7dda-4570-d480-3367c49cd2ac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: tensor([0.4300, 0.1500, 0.8900]),\n",
              " 1: tensor([0.5500, 0.8700, 0.6600]),\n",
              " 2: tensor([0.5700, 0.8500, 0.6400]),\n",
              " 3: tensor([0.2200, 0.5800, 0.3300]),\n",
              " 4: tensor([0.7700, 0.2500, 0.1000]),\n",
              " 5: tensor([0.0500, 0.8000, 0.5500])}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_in=vector.shape[-1]\n",
        "d_out=2"
      ],
      "metadata": {
        "id": "O2dC-eCsacs_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_query=nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
        "W_key=nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
        "W_value=nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)"
      ],
      "metadata": {
        "id": "LayXk0rOZ-yD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape,w_query.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHGnHamVbhBU",
        "outputId": "61d2028d-7df1-4679-e723-1366071695a1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([6, 3]), torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "querys=vector@w_query\n",
        "keys=vector@W_key\n",
        "values=vector@W_value"
      ],
      "metadata": {
        "id": "XMLlccXnblt4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "querys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY9OUObnbnfy",
        "outputId": "ebe6c320-94f5-4fc9-c6ac-9382a82d4695"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#atttention scores\n",
        "attn_scores=querys@keys.T"
      ],
      "metadata": {
        "id": "5WcWfhLndK6k"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores=attn_scores/keys.shape[-1]**0.5"
      ],
      "metadata": {
        "id": "E-p4p2FPdX8F"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights=torch.softmax(attn_scores,dim=-1)"
      ],
      "metadata": {
        "id": "tURn-c7UeC0R"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50YQQozKeHPs",
        "outputId": "1878ea5b-4eb3-40f1-a594-cb50faa591f3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1680, 0.2481, 0.2458, 0.0992, 0.1222, 0.1167],\n",
              "        [0.1688, 0.2609, 0.2593, 0.0869, 0.1234, 0.1007],\n",
              "        [0.1688, 0.2604, 0.2588, 0.0873, 0.1234, 0.1013],\n",
              "        [0.1722, 0.2140, 0.2135, 0.1216, 0.1488, 0.1299],\n",
              "        [0.1701, 0.2247, 0.2232, 0.1161, 0.1359, 0.1301],\n",
              "        [0.1730, 0.2225, 0.2222, 0.1134, 0.1475, 0.1214]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector=attn_weights@values"
      ],
      "metadata": {
        "id": "OUGiwn9tfYgc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class selfAttentionV1(nn.Module):\n",
        "  def __init__(self,d_in,d_out):\n",
        "    super().__init__()\n",
        "    self.d_in=d_in\n",
        "    self.d_out=d_out\n",
        "    self.W_query=nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
        "    self.W_key=nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
        "    self.W_value=nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
        "\n",
        "  def forward(self,X):\n",
        "    queries=X@self.W_query\n",
        "    keys=X@self.W_key\n",
        "    values=X@self.W_value\n",
        "    atten_scores=queries@keys.T\n",
        "    atten_scrores=atten_scores/keys.shape[-1]**0.5\n",
        "    atten_weights=torch.softmax(atten_scores,dim=-1)\n",
        "    context_vector=atten_weights@values\n",
        "    return context_vector"
      ],
      "metadata": {
        "id": "H6blGaGufeSR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOjkU7C7gpVc",
        "outputId": "55027c66-9495-4b7c-e366-057ede2e8806"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4300, 0.1500, 0.8900],\n",
              "        [0.5500, 0.8700, 0.6600],\n",
              "        [0.5700, 0.8500, 0.6400],\n",
              "        [0.2200, 0.5800, 0.3300],\n",
              "        [0.7700, 0.2500, 0.1000],\n",
              "        [0.0500, 0.8000, 0.5500]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selfat=selfAttentionV1(3,2)\n",
        "selfat.forward(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd7P6SwJgWIM",
        "outputId": "2075b377-793d-47df-e398-915c06f9240a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.1307, 1.3185],\n",
              "        [1.1725, 1.3639],\n",
              "        [1.1714, 1.3627],\n",
              "        [1.1378, 1.3260],\n",
              "        [1.1287, 1.3165],\n",
              "        [1.1511, 1.3404]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class selfAttentionV2(nn.Module):\n",
        "  def __init__(self,d_in,d_out):\n",
        "    super().__init__()\n",
        "    self.d_in=d_in\n",
        "    self.d_out=d_out\n",
        "    self.W_key=nn.Linear(d_in,d_out,bias=False)#use proper intitalization techniques not like random\n",
        "    self.w_value=nn.Linear(d_in,d_out,bias=False)\n",
        "    self.w_query=nn.Linear(d_in,d_out,bias=False)\n",
        "  def forward(self,X):\n",
        "    queries=self.w_query(X)\n",
        "    keys=self.W_key(X)\n",
        "    values=self.w_value(X)\n",
        "    atten_scores=queries@keys.T\n",
        "    atten_scrores=atten_scores/keys.shape[-1]**0.5\n",
        "    atten_weights=torch.softmax(atten_scores,dim=-1)\n",
        "    context_vector=atten_weights@values\n",
        "    return context_vector"
      ],
      "metadata": {
        "id": "C-giAeuggpB_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selfat=selfAttentionV1(3,2)\n",
        "selfat.forward(vector)"
      ],
      "metadata": {
        "id": "0gLnJ4E9hqGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d0c9dc-181e-40d4-95c1-61c81258ef48"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.2681, 0.5015],\n",
              "        [1.2691, 0.5104],\n",
              "        [1.2681, 0.5099],\n",
              "        [1.2249, 0.4875],\n",
              "        [1.2249, 0.4864],\n",
              "        [1.2382, 0.4950]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CASUAL ATTENTION\n"
      ],
      "metadata": {
        "id": "hLX9crRNfZ4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores=querys@keys.T\n",
        "context_length=6"
      ],
      "metadata": {
        "id": "pcfqQyMuh8w4"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask=torch.triu(torch.ones(context_length,context_length),diagonal=1)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPi-zwLkiNYb",
        "outputId": "18f97f6f-881d-49d7-ccbb-88750e5acd59"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1., 1., 1.],\n",
              "        [0., 0., 1., 1., 1., 1.],\n",
              "        [0., 0., 0., 1., 1., 1.],\n",
              "        [0., 0., 0., 0., 1., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores=attn_scores.masked_fill(mask.bool(),-torch.inf)\n",
        "attn_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nssxYfVvi3ns",
        "outputId": "9fc6c93b-520c-4a81-8d7c-d8360c37f341"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.1287,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
              "        [2.5468, 3.1628,   -inf,   -inf,   -inf,   -inf],\n",
              "        [2.5309, 3.1443, 3.1351,   -inf,   -inf,   -inf],\n",
              "        [1.3068, 1.6135, 1.6103, 0.8148,   -inf,   -inf],\n",
              "        [1.5319, 1.9256, 1.9165, 0.9918, 1.2142,   -inf],\n",
              "        [1.5586, 1.9147, 1.9125, 0.9614, 1.3336, 1.0574]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores=torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)\n",
        "attn_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WycHWT5jljl",
        "outputId": "5b472a2c-50d1-4f53-f9e8-fbd1c39836a9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3928, 0.6072, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2453, 0.3786, 0.3761, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2388, 0.2966, 0.2960, 0.1686, 0.0000, 0.0000],\n",
              "        [0.1955, 0.2583, 0.2566, 0.1334, 0.1562, 0.0000],\n",
              "        [0.1730, 0.2225, 0.2222, 0.1134, 0.1475, 0.1214]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=nn.Linear(3,2,bias=False)\n",
        "x.weight.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPD3ZlEbkaec",
        "outputId": "0e6bcab3-af83-4eae-ab35-9cc726e11e8c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CasualAttention(nn.Module):\n",
        "  def __init__(self,d_in,d_out,context_length,dropout,bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out=d_out\n",
        "    self.d_in=d_in\n",
        "    self.W_query=nn.Linear(d_in,d_out,bias=bias)\n",
        "    self.W_key=nn.Linear(d_in,d_out,bias=bias)\n",
        "    self.W_value=nn.Linear(d_in,d_out,bias=bias)\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "    self.register_buffer(\"mask\",torch.tril(torch.ones(context_length,context_length),diagonal=1))\n",
        "\n",
        "  def forward(self,X):\n",
        "    batches,num_tokens,d_in=X.shape\n",
        "    keys=self.W_key(X)\n",
        "    query=self.W_query(X)\n",
        "    value=self.W_value(X)\n",
        "    atten_scores=query@keys.transpose(1,2)\n",
        "    atten_scores.masked_fill(self.mask.bool()[:num_tokens,:num_tokens],-torch.inf)\n",
        "    atten_weights=torch.softmax(atten_scores/keys.shape[-1]**0.5,dim=-1)\n",
        "    atten_weights=self.dropout(atten_weights)\n",
        "    context_vector=atten_weights@value\n",
        "    return context_vector\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BHF2CACUTmI7"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_input=torch.stack([vector,vector])\n",
        "batch_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_vzDaagkSoi",
        "outputId": "89491634-6549-4deb-f395-02818da3801a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4300, 0.1500, 0.8900],\n",
              "         [0.5500, 0.8700, 0.6600],\n",
              "         [0.5700, 0.8500, 0.6400],\n",
              "         [0.2200, 0.5800, 0.3300],\n",
              "         [0.7700, 0.2500, 0.1000],\n",
              "         [0.0500, 0.8000, 0.5500]],\n",
              "\n",
              "        [[0.4300, 0.1500, 0.8900],\n",
              "         [0.5500, 0.8700, 0.6600],\n",
              "         [0.5700, 0.8500, 0.6400],\n",
              "         [0.2200, 0.5800, 0.3300],\n",
              "         [0.7700, 0.2500, 0.1000],\n",
              "         [0.0500, 0.8000, 0.5500]]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "casatt=CasualAttention(3,2,6,0.2)\n",
        "casatt.forward(batch_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6TS_PujWd9n",
        "outputId": "e1420113-29e7-4d62-bd20-c29342c9a6aa"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3617,  0.0130],\n",
              "         [ 0.3625,  0.0148],\n",
              "         [ 0.2481,  0.0182],\n",
              "         [ 0.3628,  0.0146],\n",
              "         [ 0.2894,  0.0154],\n",
              "         [ 0.2629, -0.0428]],\n",
              "\n",
              "        [[ 0.1984,  0.0597],\n",
              "         [ 0.3625,  0.0148],\n",
              "         [ 0.3627,  0.0149],\n",
              "         [ 0.2853,  0.0135],\n",
              "         [ 0.3269,  0.0240],\n",
              "         [ 0.1151,  0.0142]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MULI HEAD ATT\n"
      ],
      "metadata": {
        "id": "_Gf2_FcJyN1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,d_in,d_out,context_length,dropout,num_heads,bias):\n",
        "    super().__init__()\n",
        "    self.heads=nn.ModuleList(\n",
        "        CasualAttention(d_in,d_out,context_length,dropout,bias) for _ in range(num_heads)\n",
        "    )\n",
        "  def forward(self,X):\n",
        "    return torch.cat([head(X) for head in self.heads],dim=-1)"
      ],
      "metadata": {
        "id": "KqsekjfqaWp6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9ue9sD2zCb9",
        "outputId": "186e396f-f3d1-434d-a324-79db795fa75f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4300, 0.1500, 0.8900],\n",
              "         [0.5500, 0.8700, 0.6600],\n",
              "         [0.5700, 0.8500, 0.6400],\n",
              "         [0.2200, 0.5800, 0.3300],\n",
              "         [0.7700, 0.2500, 0.1000],\n",
              "         [0.0500, 0.8000, 0.5500]],\n",
              "\n",
              "        [[0.4300, 0.1500, 0.8900],\n",
              "         [0.5500, 0.8700, 0.6600],\n",
              "         [0.5700, 0.8500, 0.6400],\n",
              "         [0.2200, 0.5800, 0.3300],\n",
              "         [0.7700, 0.2500, 0.1000],\n",
              "         [0.0500, 0.8000, 0.5500]]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mah=MultiHeadAttention(3,2,6,0.2,2,False)\n",
        "mah.forward(batch_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_Sy09YSzELf",
        "outputId": "48e31669-6d10-4a35-9d6b-2a7fe8210e9d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.4557, -0.2041,  0.5008, -0.4602],\n",
              "         [ 0.3332, -0.1672,  0.3686, -0.3610],\n",
              "         [ 0.3564, -0.1933,  0.4216, -0.4182],\n",
              "         [ 0.4511, -0.2036,  0.5699, -0.4965],\n",
              "         [ 0.4509, -0.1202,  0.3701, -0.3591],\n",
              "         [ 0.4516, -0.2033,  0.4971, -0.4551]],\n",
              "\n",
              "        [[ 0.4010, -0.1005,  0.4409, -0.3983],\n",
              "         [ 0.3869, -0.1934,  0.4952, -0.4590],\n",
              "         [ 0.2385, -0.1557,  0.5038, -0.3635],\n",
              "         [ 0.3950, -0.1827,  0.4974, -0.4616],\n",
              "         [ 0.4505, -0.2047,  0.5696, -0.4976],\n",
              "         [ 0.3374, -0.0821,  0.3675, -0.3604]]], grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mah=MultiHeadAttention(3,2,6,0.2,2,False)\n",
        "mah.forward(batch_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiJjfdVwz_h3",
        "outputId": "6d4be15f-c0ab-405f-c03c-2709c33349e5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0339,  0.1292,  0.2884, -0.2583],\n",
              "         [-0.0437,  0.0980,  0.2541, -0.1264],\n",
              "         [-0.0883,  0.0593,  0.3076, -0.2193],\n",
              "         [-0.0485,  0.0281,  0.3069, -0.2182],\n",
              "         [-0.0243,  0.0654,  0.3059, -0.2191],\n",
              "         [-0.0342,  0.0918,  0.2730, -0.1701]],\n",
              "\n",
              "        [[-0.0558,  0.1043,  0.3048, -0.2173],\n",
              "         [ 0.0770,  0.0251,  0.2541, -0.1264],\n",
              "         [-0.1398,  0.1057,  0.2054, -0.1114],\n",
              "         [-0.0029,  0.0680,  0.2909, -0.2582],\n",
              "         [-0.0109,  0.0733,  0.2519, -0.1255],\n",
              "         [-0.0185,  0.0316,  0.2916, -0.2577]]], grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat([torch.tensor([[1,2,3],[5,4,6]]),torch.tensor([[1,25,56],[69,50,40]])],dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "121ZbAo11Zk3",
        "outputId": "b24ccc64-fac4-4d27-b438-6da3a7724188"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3],\n",
              "        [ 5,  4,  6],\n",
              "        [ 1, 25, 56],\n",
              "        [69, 50, 40]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,d_in,d_out,context_length,dropout,num_heads,bias):\n",
        "    super().__init__()\n",
        "    self.d_out=d_out\n",
        "    assert(self.d_out%num_heads==0)\n",
        "    self.num_heads=num_heads\n",
        "\n",
        "\n",
        "    self.d_head=self.d_out//num_heads\n",
        "    self.w_query=nn.Linear(d_in,d_out,bias=bias)\n",
        "    self.w_key=nn.Linear(d_in,d_out,bias=bias)\n",
        "    self.w_value=nn.Linear(d_in,d_out,bias=bias)\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "    self.register_buffer(\"mask\",torch.tril(torch.ones(context_length,context_length),diagonal=1))\n",
        "\n",
        "  def forward(self,X):\n",
        "    batches,num_tokens,d_in=X.shape\n",
        "    queries=self.w_query(X)\n",
        "    keys=self.w_key(X)\n",
        "    values=self.w_value(X)\n",
        "    # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "    queries = queries.view(batches, num_tokens, self.num_heads, self.d_head)\n",
        "    keys = keys.view(batches, num_tokens, self.num_heads, self.d_head)\n",
        "    values = values.view(batches, num_tokens, self.num_heads, self.d_head)\n",
        "    #  (b, num_tokens, num_heads, head_dim)->  (b, num_heads, num_tokens, head_dim)\n",
        "    queries=queries.transpose(1,2)\n",
        "    keys=keys.transpose(1,2)\n",
        "    values=values.transpose(1,2)\n",
        "    atten_scores=queries@keys.transpose(2,3)\n",
        "\n",
        "    atten_scores.masked_fill(self.mask.bool()[:num_tokens,:num_tokens],-torch.inf)\n",
        "    atten_weights=torch.softmax(atten_scores/keys.shape[-1]**0.5,dim=-1)\n",
        "\n",
        "    atten_weights=self.dropout(atten_weights)\n",
        "    context_vector=atten_weights@values\n",
        "    context_vector=context_vector.transpose(1,2).contiguous().view(batches,num_tokens,self.d_out)\n",
        "    return context_vector\n",
        "\n",
        "#contigous-brings all tensors to same memory block\n"
      ],
      "metadata": {
        "id": "jy7EfhRJ7FJN"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GPT_2\n"
      ],
      "metadata": {
        "id": "Ob6CfDE8OwhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M={\n",
        "    \"vocab_size\":50257,\n",
        "    \"n_layer\":12,\n",
        "    \"n_head\":12,\n",
        "    \"emb_dim\":768,\n",
        "    \"drop_rate\":0.1,\n",
        "    \"context_length\":258,#orginal is 1024\n",
        "    \"qkv_bias\":False\n",
        "}"
      ],
      "metadata": {
        "id": "tShWpl5rquJq"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n"
      ],
      "metadata": {
        "id": "dhAclUb-alnR"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self,emd_dim):\n",
        "    super().__init__()\n",
        "    self.eps=16-5\n",
        "    self.scale=nn.Parameter(torch.ones(emd_dim))\n",
        "    self.shift=nn.Parameter(torch.zeros(emd_dim))\n",
        "  def forward(self,X):\n",
        "    mean=X.mean(dim=-1,keepdim=True)\n",
        "    var=X.var(dim=-1,keepdim=True,unbiased=False)#unbaised as false avoid bessel correction and is divided by n not\n",
        "    norm_x=(X-mean)/torch.sqrt(var+self.eps)\n",
        "    return self.scale*norm_x+self.shift"
      ],
      "metadata": {
        "id": "zsULJGxJ0lAi"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "batch_example=torch.randn(2,5)\n",
        "layer=nn.Sequential(nn.Linear(5,5),nn.ReLU())\n",
        "LayerNor=LayerNorm(5)\n",
        "LayerNor.forward(layer(batch_example))"
      ],
      "metadata": {
        "id": "citjjV-52DO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6c9645-83f4-4c4e-96b5-f6a6c57289e2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1740, -0.0804, -0.0414,  0.0281, -0.0804],\n",
              "        [-0.1409,  0.3822,  0.0407, -0.1409, -0.1409]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  def forward(self,X):\n",
        "    return 0.5*X*(1+torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0/torch.pi))*(X+0.044715*torch.pow(X,3))\n",
        "        ))"
      ],
      "metadata": {
        "id": "3ytJ7rgZ-CZb"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    #expansion and contraction helps in laerning more from data\n",
        "    self.layers=nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]),#Expamisom\n",
        "        GELU(),\n",
        "        nn.Linear(4*cfg[\"emb_dim\"],cfg[\"emb_dim\"]),#contraction\n",
        "\n",
        "    )\n",
        "  def forward(self,X):\n",
        "    return self.layers(X)\n"
      ],
      "metadata": {
        "id": "V7AJ5D1Znym1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.att=MultiHeadAttention(\n",
        "        d_in=cfg[\"emb_dim\"],\n",
        "        d_out=cfg[\"emb_dim\"],\n",
        "        context_length=cfg[\"context_length\"],\n",
        "        dropout=cfg[\"drop_rate\"],\n",
        "        num_heads=cfg[\"n_head\"],\n",
        "        bias=cfg[\"qkv_bias\"]\n",
        "    )\n",
        "    self.ff=FeedForward(cfg)\n",
        "    self.norm1=LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2=LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut=nn.Dropout(cfg[\"drop_rate\"])\n",
        "  def forward(self,X):\n",
        "    shortcut=X\n",
        "    X=self.norm1(X)\n",
        "    X=self.att(X)\n",
        "    X=self.drop_shortcut(X)\n",
        "    X=X+shortcut\n",
        "    shortcut=X\n",
        "    X=self.norm2(X)\n",
        "    X=self.ff(X)\n",
        "    X=self.drop_shortcut(X)\n",
        "    X=X+shortcut\n",
        "\n",
        "    return X\n",
        "\n"
      ],
      "metadata": {
        "id": "loIZdPVJsTSE"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer=TransformerBlock(GPT_CONFIG_124M)\n",
        "X=torch.randn(2,4,768)\n",
        "transformer.forward(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijwqKK4qEunk",
        "outputId": "b97fff4d-bb9d-4998-d831-998b3bfeff11"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.8517,  1.2771,  0.5991,  ...,  0.6316,  0.1851, -0.7436],\n",
              "         [-0.2482,  0.3575, -1.9244,  ...,  1.1176,  1.5551, -0.4224],\n",
              "         [ 0.8012, -0.4539,  0.7029,  ..., -0.9050, -1.1018, -2.4742],\n",
              "         [ 0.1222, -0.3102,  1.2451,  ..., -1.5321,  1.5540, -0.4453]],\n",
              "\n",
              "        [[ 0.9676, -0.2311,  0.6034,  ...,  0.6068, -0.0134, -0.8894],\n",
              "         [-0.9767,  0.3990,  2.2380,  ...,  0.0290, -0.0741, -1.1922],\n",
              "         [ 0.4782, -0.2527, -1.4794,  ..., -0.4689,  0.7113,  0.0239],\n",
              "         [ 0.5409,  1.3880, -1.6599,  ..., -0.7938, -1.7315,  0.8465]]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.token_emb=nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
        "    self.pos_emb=nn.Embedding(cfg[\"context_length\"],cfg[\"emb_dim\"])\n",
        "\n",
        "    self.tblocks=nn.Sequential(\n",
        "        *[TransformerBlock(cfg) for _ in range(cfg[\"n_layer\"])]\n",
        "    )\n",
        "    self.norm=LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head=nn.Linear(\n",
        "        cfg[\"emb_dim\"],\n",
        "        cfg[\"vocab_size\"],\n",
        "        bias=False\n",
        "    )\n",
        "    self.drop_emb=nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self,in_idx):\n",
        "    batch_size,context_length=in_idx.shape\n",
        "    token_emb=self.token_emb(in_idx)\n",
        "    pos_emb=self.pos_emb(torch.arange(context_length,device=in_idx.device))\n",
        "    X=token_emb+pos_emb\n",
        "    X=self.drop_emb(X)\n",
        "    X=self.tblocks(X)\n",
        "    X=self.norm(X)\n",
        "    logits=self.out_head(X)\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "BZ1unG0myZEG"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_input=torch.randint(1000,5000,(2,4))\n",
        "\n",
        "model=GPTModel(GPT_CONFIG_124M)\n",
        "model.forward(batch_input).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgiFNRVuQn5n",
        "outputId": "56857c68-151a-45da-d353-6ee64d2fc823"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 50257])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNxXaBsqge0r",
        "outputId": "f9955dd2-a81c-46ca-f672-0dee93365239"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params=sum(p.numel() for p in model.parameters())\n",
        "total_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qU9o5V7aVUD",
        "outputId": "5a2ac190-906f-4653-c60a-aae838fc4b5e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "155334144"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BIr-WsGWa8Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_params-sum(p.numel() for p in model.out_head.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XBHMlK8afrJ",
        "outputId": "b9b890ba-3392-4a8b-da1e-404372623ee5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116736768"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model,idx,max_new_tokens,context_size):\n",
        "  for _ in range (max_new_tokens):\n",
        "    idx_cond=idx[:,-context_size:]\n",
        "    logits=model(idx_cond)\n",
        "    logits=logits[:,-1,:]\n",
        "    probs=torch.softmax(logits,dim=-1)\n",
        "    idx_next=torch.argmax(probs,dim=-1,keepdims=True)\n",
        "    idx=torch.concat([idx,idx_next],dim=-1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "viVs8hQHbMUw"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input1=\"hello how are\"\n",
        "target1=\"how are you\"\n",
        "input2=\"did uou know\"\n",
        "target2=\"you know that\"\n",
        "input=torch.tensor(tokenizer.encode(input1)).unsqueeze(0)\n",
        "target=torch.tensor(tokenizer.encode(target1)).unsqueeze(0)\n",
        "input2=torch.tensor(tokenizer.encode(input2)).unsqueeze(0)\n",
        "target2=torch.tensor(tokenizer.encode(target2)).unsqueeze(0)\n",
        "pred=generate_text_simple(model,input,3,4)\n",
        "tokenizer.decode(pred[0].tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0nAbquEwdOAz",
        "outputId": "52e8b1de-c55b-433c-fa75-d81691fc3753"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello how areagnar revolutionaries +='"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input=torch.tensor([[16833,3626,6100],\n",
        "                      [40,1107,588]])\n",
        "target=torch.tensor([[3626,6100,345],\n",
        "                    [1107,588,11311]])\n",
        "input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfTngAigcuq4",
        "outputId": "27aeaa5a-343c-410a-9b25-63711e639b8f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=GPTModel(GPT_CONFIG_124M)"
      ],
      "metadata": {
        "id": "doB6d7WZf59K"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits=model.forward(input)\n",
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLpiUwcDqIa8",
        "outputId": "c1ff0140-2ff3-40a0-fd16-6a59c583aae9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 50257])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits=torch.softmax(logits,dim=-1)\n",
        "logits"
      ],
      "metadata": {
        "id": "mKqijGu1fcMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7366579a-1b78-404e-bd0e-a9a3a5e7f6b4"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.7509e-05, 2.0656e-05, 1.4978e-05,  ..., 2.4582e-05,\n",
              "          1.3785e-05, 3.2439e-05],\n",
              "         [1.6156e-05, 1.8522e-05, 2.1794e-05,  ..., 3.0743e-05,\n",
              "          2.8834e-05, 2.3746e-05],\n",
              "         [1.5961e-05, 9.1822e-06, 1.2456e-05,  ..., 1.8006e-05,\n",
              "          2.0569e-05, 2.4180e-05]],\n",
              "\n",
              "        [[1.9381e-05, 2.1054e-05, 1.6801e-05,  ..., 2.2823e-05,\n",
              "          1.7227e-05, 1.7701e-05],\n",
              "         [1.8539e-05, 1.8340e-05, 2.9077e-05,  ..., 2.7240e-05,\n",
              "          2.2755e-05, 1.7774e-05],\n",
              "         [1.7788e-05, 1.2387e-05, 2.4298e-05,  ..., 2.4481e-05,\n",
              "          1.5539e-05, 2.0659e-05]]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ysv7RQpSUCTK",
        "outputId": "624fcb10-9cae-477f-db83-11deef7b5072"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3626, 6100,  345])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_prob1=logits[0,[0,1,2],target[0]]\n",
        "\n",
        "target_prob2=logits[1,[0,1,2],target[1]]\n",
        "target_prob1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH7k8Dnhb15C",
        "outputId": "520b781d-b93b-4077-cec0-63d90983257c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.9933e-05, 3.0146e-05, 1.3860e-05], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_probs=torch.log(torch.cat((target_prob1,target_prob2)))\n",
        "avg_log_probs=torch.mean(log_probs)\n",
        "cross_entopy_loss=-avg_log_probs\n",
        "cross_entopy_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZhPE7E9hN5G",
        "outputId": "3906dc76-1623-4bc8-b9ed-20219df9036c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.8841, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape,target.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnFFC6knibcN",
        "outputId": "dbb15e6c-5ad2-4baf-d1e2-b47641b7a800"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3, 50257]), torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using torch module\n"
      ],
      "metadata": {
        "id": "9YLA276QjERO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits_flatten=logits.flatten(0,1)\n",
        "target_flatten=target.flatten()"
      ],
      "metadata": {
        "id": "xNCgpQIUimHb"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits_flatten.shape,target_flatten.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXqU8iNBivLa",
        "outputId": "9c14adaa-409c-457c-a126-fc0a136299ab"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([6, 50257]), torch.Size([6]))"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_loss=torch.nn.functional.cross_entropy(logits_flatten,target_flatten)\n",
        "cross_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-fhIup0iyMO",
        "outputId": "29a41e25-43b2-4880-aa96-f2d7bf21f686"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.8249, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch,target_batch,model,device):\n",
        "  input_batch=input_batch.to(device)\n",
        "  target_batch=target_batch.to(device)\n",
        "  logits=model(input_batch)\n",
        "  loss=torch.nn.functional.cross_entropy(logits.flatten(0,1),target_batch.flatten())\n",
        "  return loss"
      ],
      "metadata": {
        "id": "NdLfu2kJJxYM"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "file_path=\"the-verdict.txt\"\n",
        "url=\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "  with urllib.request.urlopen(url) as response:\n",
        "    text_data=response.read().decode('utf-8')\n",
        "  with open(file_path,'w',encoding=\"utf-8\") as f:\n",
        "    f.write(text_data)\n",
        "else:\n",
        "  with open(file_path,\"r\",encoding=\"utf-8\") as rf:\n",
        "    text_data=rf.read()\n"
      ],
      "metadata": {
        "id": "BoMOzMini_g0"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3Hz77wWmuXu",
        "outputId": "53eb958c-5268-454f-a3d5-8c776741dac1"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20479"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer=tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "cFzGhpeAmzSv"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio=0.90\n",
        "split_idx=int(train_ratio*len(text_data))\n",
        "train_data=text_data[:split_idx]\n",
        "val_data=text_data[split_idx:]"
      ],
      "metadata": {
        "id": "tvCKLkpv9qUk"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=create_dataloader(\n",
        "    train_data,batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    shuffle=True,\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    num_workers=0\n",
        ")\n",
        "val_loader=create_dataloader(\n",
        "    val_data,batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "fFfoHYgg60ZU"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(val_loader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aNI3Auj491hb",
        "outputId": "1bee3090-1045-4a26-ea57-f8c489d4b3e1"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  518,     6, 14707,   588,   257,  2156,   286,  4116,    13,   679,\n",
            "          1422,   470, 10505,   263,    11,   345,  1833,    11,  3595,   520,\n",
            "          5493,   438,   258,   655,  3830,   612, 12703,  4964,    11,   290,\n",
            "           319,   465, 11914,    11,   832,   262, 12768, 21213,    11,   314,\n",
            "          3947,   284,  3285,   262,  1808,    25,   705,  8491,   345,  1654,\n",
            "           345,   760,   810,   345,   821,  2406,   503,  8348,   198,   198,\n",
            "             1,  1532,   314,   714,   423, 13055,   326,  1986,    11,   351,\n",
            "           326,  1808,   319,   340,    11,   314,   815,   423,  1760,   257,\n",
            "          1049,  1517,    13,   383,  1306,  6000,  1517,   373,   284,   766,\n",
            "           326,   314,  3521,   470,   438,   392,   326, 11542,   373,  1813,\n",
            "           502,    13,   887,    11, 11752,    11,   379,   326,  5664,    11,\n",
            "          8759,  2763,    11,   373,   612,  1997,   319,  4534,   314,  3636,\n",
            "           470,   423,  1813,   284,   423,   520,  5493,  6776,   878,   502,\n",
            "            11,   290,   284,  3285,   683,   910,    25,   705,  1026,   338,\n",
            "           407,  1165,  2739,   438,    40,  1183,   905,   345,   703, 30960,\n",
            "           198,   198,     1,  1026,  4808,  9776,    62,  1165,  2739,   438,\n",
            "           270,   561,   423,   587,    11,   772,   611,   339,  1549,   587,\n",
            "          6776,    13,   314, 11856,   510,   616, 20348,    11,   290,  1816,\n",
            "           866,   290,  1297,  9074,    13,   520,  5493,    13,  3226,  1781,\n",
            "           314,  1422,   470,  1560,   607,  4808,  5562,    62,   438,   270,\n",
            "           561,   423,   587,  8312,   284,   607,    13,   314,  2391,   531,\n",
            "           314,  3521,   470,  7521,   683,    11,   326,   314,   373,  1165,\n",
            "          3888,    13,  1375,  2138,  8288,   262,  2126,   438,  7091,   338,\n",
            "           523, 14348,     0,   632,   373,   326,   326,   925,   607,  1577,\n",
            "           502,   262, 50085,    13,   887,   673,   373, 22121,  9247,   379,\n",
            "           407,  1972,   262, 18560,   438,  7091,   750,   523],\n",
            "        [  765,   683,   705, 28060,     6,   416,   617,   530,   905,    88,\n",
            "             0,  1629,   717,   314,   373,  7787,   673,  3636,   470,  1309,\n",
            "           502,   572,   438,   392,   379,   616,   266,   896,     6,   886,\n",
            "           314,  5220, 41379,   293,    13,  3363,    11,   340,   373,   314,\n",
            "           508,  2067, 41379,   293,    25,   314,  1297,  9074,    13,   520,\n",
            "          5493,   339,   373,   262,   705,  4976,     6,   582,    11,   290,\n",
            "           673,  1297,  8276,  2073,    11,   290,   523,   340,  1392,   284,\n",
            "           307,  2081,    13,   764,   764,   764,   843,   339, 13055,   520,\n",
            "          5493,  1231,  1592,  2259,    26,   290,   673,  9174,   262,  4286,\n",
            "          1871,   607,  5229,   338,  1243,    13,   764,   764, 22135,   198,\n",
            "           198,  1544, 45111,  2241,   866,   287,   262,  3211,    12, 16337,\n",
            "          1474,  6164,    11,  8104,   736,   465,  1182,    11,   290, 47425,\n",
            "           278,   465,  5101, 11061,   340,    11,  3114,   510,   379,   262,\n",
            "          4286,  2029,   262, 18205,  1681,    12, 12239,    13,   198,   198,\n",
            "             1,    40,   588,   284, 14996,   326,   520,  5493,  2241,   561,\n",
            "           423,  1813,   340,   284,   502,    11,   611,   339,  1549,   587,\n",
            "          1498,   284,   910,   644,   339,  1807,   326,  1110,   526,   198,\n",
            "           198,  1870,    11,   287,  3280,   284,   257,  1808,   314,  1234,\n",
            "          2063,    12,  1326,  3147,  1146,   438,     1, 44140,   757,  1701,\n",
            "           339, 30050,   503,    13,   366,  2215,   262,   530,  1517,   326,\n",
            "          6774,   502,  6609,  1474,   683,   318,   326,   314,  2993,  1576,\n",
            "           284,  2666,   572,  1701,   198,   198,  1544,  6204,   510,   290,\n",
            "          8104,   465,  1021,   319,   616,  8163,   351,   257,  6487,    13,\n",
            "           366, 10049,   262, 21296,   286,   340,   318,   326,   314,  4808,\n",
            "           321,    62,   991, 12036,   438, 20777, 41379,   293,   338,  1804,\n",
            "           340,   329,   502,     0,   383,   520,  5493,    82]]), tensor([[    6, 14707,   588,   257,  2156,   286,  4116,    13,   679,  1422,\n",
            "           470, 10505,   263,    11,   345,  1833,    11,  3595,   520,  5493,\n",
            "           438,   258,   655,  3830,   612, 12703,  4964,    11,   290,   319,\n",
            "           465, 11914,    11,   832,   262, 12768, 21213,    11,   314,  3947,\n",
            "           284,  3285,   262,  1808,    25,   705,  8491,   345,  1654,   345,\n",
            "           760,   810,   345,   821,  2406,   503,  8348,   198,   198,     1,\n",
            "          1532,   314,   714,   423, 13055,   326,  1986,    11,   351,   326,\n",
            "          1808,   319,   340,    11,   314,   815,   423,  1760,   257,  1049,\n",
            "          1517,    13,   383,  1306,  6000,  1517,   373,   284,   766,   326,\n",
            "           314,  3521,   470,   438,   392,   326, 11542,   373,  1813,   502,\n",
            "            13,   887,    11, 11752,    11,   379,   326,  5664,    11,  8759,\n",
            "          2763,    11,   373,   612,  1997,   319,  4534,   314,  3636,   470,\n",
            "           423,  1813,   284,   423,   520,  5493,  6776,   878,   502,    11,\n",
            "           290,   284,  3285,   683,   910,    25,   705,  1026,   338,   407,\n",
            "          1165,  2739,   438,    40,  1183,   905,   345,   703, 30960,   198,\n",
            "           198,     1,  1026,  4808,  9776,    62,  1165,  2739,   438,   270,\n",
            "           561,   423,   587,    11,   772,   611,   339,  1549,   587,  6776,\n",
            "            13,   314, 11856,   510,   616, 20348,    11,   290,  1816,   866,\n",
            "           290,  1297,  9074,    13,   520,  5493,    13,  3226,  1781,   314,\n",
            "          1422,   470,  1560,   607,  4808,  5562,    62,   438,   270,   561,\n",
            "           423,   587,  8312,   284,   607,    13,   314,  2391,   531,   314,\n",
            "          3521,   470,  7521,   683,    11,   326,   314,   373,  1165,  3888,\n",
            "            13,  1375,  2138,  8288,   262,  2126,   438,  7091,   338,   523,\n",
            "         14348,     0,   632,   373,   326,   326,   925,   607,  1577,   502,\n",
            "           262, 50085,    13,   887,   673,   373, 22121,  9247,   379,   407,\n",
            "          1972,   262, 18560,   438,  7091,   750,   523,   765],\n",
            "        [  683,   705, 28060,     6,   416,   617,   530,   905,    88,     0,\n",
            "          1629,   717,   314,   373,  7787,   673,  3636,   470,  1309,   502,\n",
            "           572,   438,   392,   379,   616,   266,   896,     6,   886,   314,\n",
            "          5220, 41379,   293,    13,  3363,    11,   340,   373,   314,   508,\n",
            "          2067, 41379,   293,    25,   314,  1297,  9074,    13,   520,  5493,\n",
            "           339,   373,   262,   705,  4976,     6,   582,    11,   290,   673,\n",
            "          1297,  8276,  2073,    11,   290,   523,   340,  1392,   284,   307,\n",
            "          2081,    13,   764,   764,   764,   843,   339, 13055,   520,  5493,\n",
            "          1231,  1592,  2259,    26,   290,   673,  9174,   262,  4286,  1871,\n",
            "           607,  5229,   338,  1243,    13,   764,   764, 22135,   198,   198,\n",
            "          1544, 45111,  2241,   866,   287,   262,  3211,    12, 16337,  1474,\n",
            "          6164,    11,  8104,   736,   465,  1182,    11,   290, 47425,   278,\n",
            "           465,  5101, 11061,   340,    11,  3114,   510,   379,   262,  4286,\n",
            "          2029,   262, 18205,  1681,    12, 12239,    13,   198,   198,     1,\n",
            "            40,   588,   284, 14996,   326,   520,  5493,  2241,   561,   423,\n",
            "          1813,   340,   284,   502,    11,   611,   339,  1549,   587,  1498,\n",
            "           284,   910,   644,   339,  1807,   326,  1110,   526,   198,   198,\n",
            "          1870,    11,   287,  3280,   284,   257,  1808,   314,  1234,  2063,\n",
            "            12,  1326,  3147,  1146,   438,     1, 44140,   757,  1701,   339,\n",
            "         30050,   503,    13,   366,  2215,   262,   530,  1517,   326,  6774,\n",
            "           502,  6609,  1474,   683,   318,   326,   314,  2993,  1576,   284,\n",
            "          2666,   572,  1701,   198,   198,  1544,  6204,   510,   290,  8104,\n",
            "           465,  1021,   319,   616,  8163,   351,   257,  6487,    13,   366,\n",
            "         10049,   262, 21296,   286,   340,   318,   326,   314,  4808,   321,\n",
            "            62,   991, 12036,   438, 20777, 41379,   293,   338,  1804,   340,\n",
            "           329,   502,     0,   383,   520,  5493,    82,  1302]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in train_loader:\n",
        "  print(x.shape,y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeQBbVgaFDAl",
        "outputId": "b0f5c5de-7782-4032-f433-6ba446308e72"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 258]) torch.Size([2, 258])\n",
            "torch.Size([2, 258]) torch.Size([2, 258])\n",
            "torch.Size([2, 258]) torch.Size([2, 258])\n",
            "torch.Size([2, 258]) torch.Size([2, 258])\n",
            "torch.Size([2, 258]) torch.Size([2, 258])\n",
            "torch.Size([2, 258]) torch.Size([2, 258])\n",
            "torch.Size([2, 258]) torch.Size([2, 258])\n",
            "torch.Size([2, 258]) torch.Size([2, 258])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
        "  total_loss=0\n",
        "  if len(data_loader)==0:\n",
        "    return float(\"nan\")\n",
        "  elif(num_batches is None):\n",
        "    num_batches=len(data_loader)\n",
        "  else:\n",
        "    num_batches=min(num_batches,len(data_loader))\n",
        "  for i,(x,y) in enumerate(data_loader):\n",
        "    if i<num_batches:\n",
        "      loss=calc_loss_batch(x,y,model,device)\n",
        "      total_loss+=loss.item()\n",
        "    else:\n",
        "      break\n",
        "    return total_loss/num_batches\n"
      ],
      "metadata": {
        "id": "DDMqmx97FNrk"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YqB3AHHtMbkx",
        "outputId": "d693290c-d40a-459c-ec46-95f44823ca2c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (token_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(258, 768)\n",
              "  (tblocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "  train_loss=calc_loss_loader(train_loader,model,device)\n",
        "  val_loss=calc_loss_loader(val_loader,model,device)\n",
        "print(\"Training loss:\",train_loss)\n",
        "print(\"Validation loss:\",val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AScfxrgLsgh",
        "outputId": "cceb9e1e-7333-49c7-90d4-64d025a9fd6c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.3563482761383057\n",
            "Validation loss: 10.843839645385742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(start_context,tokenizer):\n",
        "  return torch.tensor(tokenizer.encode(start_context)).unsqueeze(0)\n",
        "def token_ids_to_text(token_ids,tokenizer):\n",
        "  return tokenizer.decode(token_ids.tolist()[0])"
      ],
      "metadata": {
        "id": "bHcpvwSxju_C"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_and_print(model,tokenizer,device,start_context):\n",
        "  model.eval()\n",
        "  context_size=model.pos_emb.weight.shape[0]\n",
        "  encode=text_to_token_ids(start_context,tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    token_ids=generate_text_simple(model,encode,context_size=context_size,max_new_tokens=50)\n",
        "  decoded_text=token_ids_to_text(token_ids,tokenizer)\n",
        "  print(decoded_text.replace(\"\\n\",\"\"))\n",
        "  model.train()"
      ],
      "metadata": {
        "id": "bYlZ2DBMh2tf"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss=calc_loss_loader(train_loader,model,device,eval_iter)\n",
        "    val_loss=calc_loss_loader(val_loader,model,device,eval_iter)\n",
        "  model.train()\n",
        "  return train_loss,val_loss"
      ],
      "metadata": {
        "id": "io3MoFyzktsT"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter,start_context,tokenizer):\n",
        "  train_losses=[]\n",
        "  val_losses=[]\n",
        "  track_tokens_seen=[]\n",
        "  tokens_seen=0\n",
        "  global_step=-1\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    for input_batch,target_batch in train_loader:\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss=calc_loss_batch(input_batch,target_batch,model,device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen+=input_batch.numel()\n",
        "      global_step+=1\n",
        "      if global_step % eval_freq==0:\n",
        "        train_loss,val_loss=evaluate_model(model,train_loader,val_loader,device,eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Epoch{epoch+1} loss {train_loss:.4f} val_loss {val_loss:.4f}\")\n",
        "    generate_text_and_print(model,tokenizer,device,start_context)\n",
        "  return train_losses,val_losses,track_tokens_seen\n"
      ],
      "metadata": {
        "id": "9mX256c3biJD"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qHSAXhrYc23U"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model=GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer=torch.optim.AdamW(model.parameters(),lr=1e-4,weight_decay=0.1)\n",
        "num_epochs=5\n",
        "input=\"What a wonder\"\n",
        "train_losses,val_losses,tokens_seen=train_model(model,train_loader,val_loader,\n",
        "                                                optimizer,device,num_epochs,5,5,input,tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU4vtwsNhhM_",
        "outputId": "1f141717-734a-4654-8c0b-20607ae969e7"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch1 loss 2.1623 val_loss 10.8150\n",
            "Epoch1 loss 2.0862 val_loss 10.5680\n",
            "What a wonder, the,, and, the, the.\n",
            "Epoch2 loss 1.9252 val_loss 9.7310\n",
            "Epoch2 loss 1.7115 val_loss 8.7149\n",
            "What a wonder,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Epoch3 loss 1.6094 val_loss 8.1658\n",
            "What a wonder,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Epoch4 loss 1.4646 val_loss 7.7029\n",
            "Epoch4 loss 1.3747 val_loss 7.3157\n",
            "What a wonder,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Epoch5 loss 1.3333 val_loss 7.0400\n",
            "What a wonder,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Epoch6 loss 1.2968 val_loss 6.8444\n",
            "Epoch6 loss 1.2760 val_loss 6.7316\n",
            "What a wonder, the,, the, the, the, the, the, the, the,, the,, the, the, the, the, the, the, the, the, the,, the,, the, the, the,\n",
            "Epoch7 loss 1.2687 val_loss 6.6439\n",
            "Epoch7 loss 1.1963 val_loss 6.6002\n",
            "What a wonder,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Epoch8 loss 1.1938 val_loss 6.5809\n",
            "What a wonder, the, the, the, the, the, the, the, the, the, the,, the, the, the, the, the, the, the, the, the,, the, the, the, the, the\n",
            "Epoch9 loss 1.1721 val_loss 6.5766\n",
            "Epoch9 loss 1.1655 val_loss 6.5577\n",
            "What a wonder, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the\n",
            "Epoch10 loss 1.2097 val_loss 6.5184\n",
            "What a wonder, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the\n",
            "Epoch11 loss 1.1488 val_loss 6.4895\n",
            "Epoch11 loss 1.1696 val_loss 6.4665\n",
            "What a wonder, the, and, the, the, the, and, the, the, the, the, the, the, and, the, the, the, the, the, the, the, the, the, the, and, and\n",
            "Epoch12 loss 1.1507 val_loss 6.4283\n",
            "Epoch12 loss 1.0694 val_loss 6.4034\n",
            "What a wonder, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and the, and, and, and, and, and, and, and, and, and,\n",
            "Epoch13 loss 1.0674 val_loss 6.3989\n",
            "What a wonder.\n",
            "Epoch14 loss 1.0386 val_loss 6.3200\n",
            "Epoch14 loss 1.0704 val_loss 6.2876\n",
            "What a wonder of the--I was, and, and, and I had the--I, and I had, and I had, and of the--I the-- I had the--I of the.\n",
            "Epoch15 loss 1.0455 val_loss 6.2914\n",
            "What a wonder of the \"\n",
            "Epoch16 loss 0.9723 val_loss 6.2548\n",
            "Epoch16 loss 0.9876 val_loss 6.2556\n",
            "What a wonder of the \"\n",
            "Epoch17 loss 0.9185 val_loss 6.2204\n",
            "Epoch17 loss 0.9507 val_loss 6.2076\n",
            "What a wonder of the of the of the of the of the of the, and had of the of the of the, and, and, and of the of the of the of the of the of the of the, and, and of the of the of\n",
            "Epoch18 loss 0.9062 val_loss 6.2061\n",
            "What a wonder of the picture, and, and, and, the of the of the of the of the of the, and it was, the of the of the of the of the of the of the of the--as, it was, and, and\n",
            "Epoch19 loss 0.9075 val_loss 6.2079\n",
            "Epoch19 loss 0.8711 val_loss 6.1836\n",
            "What a wonder of the picture was his--as, and, and had been the last of the of the of the- of the of the of the picture of the of the of the of the of the his painting, and, and it was, and it\n",
            "Epoch20 loss 0.8498 val_loss 6.1870\n",
            "What a wonder of the picture was his painting.\n",
            "Epoch21 loss 0.8428 val_loss 6.1565\n",
            "Epoch21 loss 0.8072 val_loss 6.1864\n",
            "What a wonder of the last Gisburn's the last to the picture, the last of the the last was, and Mrs.\n",
            "Epoch22 loss 0.7254 val_loss 6.2076\n",
            "Epoch22 loss 0.7980 val_loss 6.1482\n",
            "What a wonder of the picture was his painting, and Mrs.\n",
            "Epoch23 loss 0.7773 val_loss 6.1692\n",
            "What a wonder of the picture had been the last to have to the of the of the of the the his the had the picture to the picture of the picture of the of the his own of the of the his painting, of the it was his of the picture\n",
            "Epoch24 loss 0.6227 val_loss 6.1672\n",
            "Epoch24 loss 0.6725 val_loss 6.2034\n",
            "What a wonder of his own was his painting, the last to the picture had the last of the the it was his own his painting of the last was his own his own his painting, and I had the his painting, the last it was his own his own\n",
            "Epoch25 loss 0.6899 val_loss 6.1958\n",
            "What a wonder of the last Gisburn had been that, the picture had the last of the of the it had been his painting, and had been the picture had been his painting, of the of the his painting, of the it was his own, and\n",
            "Epoch26 loss 0.6273 val_loss 6.2341\n",
            "Epoch26 loss 0.5927 val_loss 6.2146\n",
            "What a wonder his painting.\n",
            "Epoch27 loss 0.5568 val_loss 6.2629\n",
            "Epoch27 loss 0.5557 val_loss 6.2493\n",
            "What a wonder of Jack's Gisburn had been that, the picture had the last of the of the picture had been his painting of Jack's his painting that the last had been his own of the picture of the last of the it was his own of the\n",
            "Epoch28 loss 0.6103 val_loss 6.2521\n",
            "What a wonder of Jack's Gisburn had been that, the picture had the last of the of the picture had been his painting of Jack's his painting that the last had been his own of the picture of the last of the it was his own of Jack\n",
            "Epoch29 loss 0.5573 val_loss 6.2578\n",
            "Epoch29 loss 0.5435 val_loss 6.2409\n",
            "What a wonder of Jack's Gisburn had been that, the picture had the last of the of the last had been his painting of Jack's his painting; and Mrs. Gisburn had the last his painting, of his pictures of his eyes to the\n",
            "Epoch30 loss 0.5349 val_loss 6.2355\n",
            "What a wonder of Jack's Gisburn had been that, the picture had the last of the of Jack Gisburn had the picture to the picture. Gisburn had been his--as of the picture--as of the it was his eyes to the\n",
            "Epoch31 loss 0.5611 val_loss 6.2752\n",
            "Epoch31 loss 0.4421 val_loss 6.2650\n",
            "What a wonder of Jack's Gisburn had been that, the picture, the last of the of Jack Gisburn had been Jack, the picture, in the picture had been his own of the picture of the last of the it was his own, and\n",
            "Epoch32 loss 0.4188 val_loss 6.3280\n",
            "Epoch32 loss 0.4478 val_loss 6.3236\n",
            "What a wonder of Jack's Gisburn had been that, the picture had the last of the of Jack Gisburn had the picture to the picture. Gisburn had been his own of the picture. Gisburn had it was his eyes, and\n",
            "Epoch33 loss 0.4299 val_loss 6.3160\n",
            "What a wonder of Jack's Gisburn had been that, the picture had the last of the of Jack Gisburn had the picture to the picture of Jack's his own it had been his own of his painting, of his it was his own of Jack\n",
            "Epoch34 loss 0.3765 val_loss 6.3615\n",
            "Epoch34 loss 0.3719 val_loss 6.3577\n",
            "What a wonder! I had been his own a little at the picture--his not had the Riviera, it had been me to Mrs. Gisburn had the last had been his own her own his own a--it was it was his own his own\n",
            "Epoch35 loss 0.3803 val_loss 6.4010\n",
            "What a wonder!\n",
            "Epoch36 loss 0.4202 val_loss 6.3937\n",
            "Epoch36 loss 0.3605 val_loss 6.3672\n",
            "What a wonder! I had been his own a little at the honour--his with a good- of Jack Gisburn--as Jack, the picture. Gisburn had been his own her own a his painting, of his pictures of his own his own\n",
            "Epoch37 loss 0.3849 val_loss 6.4014\n",
            "Epoch37 loss 0.3710 val_loss 6.4002\n",
            "What a wonder! I had been his own picture--his had the picture--his had the Mrs. Gisburn's \"Yes--I had been a good the last had been his own her own a little on the last I had been his own, and\n",
            "Epoch38 loss 0.3639 val_loss 6.4349\n",
            "What a wonder! I had been his painting. Gisburn had a little of Jack--his of Jack Gisburn had the had been the picture. Gisburn had been his own her own a little on the last were, in his eyes on the\n",
            "Epoch39 loss 0.3317 val_loss 6.4393\n",
            "Epoch39 loss 0.3184 val_loss 6.4420\n",
            "What a wonder! I had been his own picture--his had the picture to the fact that, the Riviera, the last Jack's Mrs. Gisburn had been his painting; and Mrs. Gisburn--it was it was his eyes on the\n",
            "Epoch40 loss 0.2981 val_loss 6.4517\n",
            "What a wonder! I had been his own picture--his had the picture to the fact that, the Gisburn's resolve had been taken. Gisburn had been his painting; and Mrs. Gisburn had always, it was his own himself on\n",
            "Epoch41 loss 0.2741 val_loss 6.4995\n",
            "Epoch41 loss 0.2657 val_loss 6.4716\n",
            "What a wonder of her own picture--as Jack's past!\n",
            "Epoch42 loss 0.2882 val_loss 6.4893\n",
            "Epoch42 loss 0.2398 val_loss 6.5312\n",
            "What a wonder! I had been his own picture--his had the picture--his Gisburn had been his pictures--the and Mrs. \"The and in the Riviera, had been his own sitters had been his painting, on the picture--his\n",
            "Epoch43 loss 0.2220 val_loss 6.5363\n",
            "What a wonder! I had been his own picture--his had the picture to the fact of Mrs. Gisburn's resolve had been taken. Gisburn had been his painting; and Mrs. Gisburn had always were, on his own sitters\n",
            "Epoch44 loss 0.2578 val_loss 6.5714\n",
            "Epoch44 loss 0.1915 val_loss 6.5466\n",
            "What a wonder!\n",
            "Epoch45 loss 0.2567 val_loss 6.5674\n",
            "What a wonder!\n",
            "Epoch46 loss 0.1950 val_loss 6.5957\n",
            "Epoch46 loss 0.1999 val_loss 6.6512\n",
            "What a wonder! I had been his own picture--his had the picture to the fact that Mrs. Gisburn's resolve had been taken. Gisburn had been his painting; and Mrs. Gisburn--it was it was his eyes on Jack\n",
            "Epoch47 loss 0.2013 val_loss 6.6667\n",
            "Epoch47 loss 0.1920 val_loss 6.6606\n",
            "What a wonder! I had been his painting. Gisburn had been through the fact that Mrs. Gisburn had been his own! \"It's \"strongest had been his admirers would have put it--it was it was his eyes on the\n",
            "Epoch48 loss 0.1910 val_loss 6.6820\n",
            "What a wonder! I had been his own picture--his had the picture to the fact that Mrs. Gisburn's resolve had been taken. Gisburn had been his painting; and Mrs. Gisburn--it was it was his eyes on the\n",
            "Epoch49 loss 0.1639 val_loss 6.7196\n",
            "Epoch49 loss 0.1474 val_loss 6.7008\n",
            "What a wonder! I had been his last word, in the honour being _mine were amusing himself by holding it had been me to me to see Jack's \"strongest had been his admirers would have put it--it was rich on his eyes on the\n",
            "Epoch50 loss 0.1386 val_loss 6.7153\n",
            "What a wonder! I had been his last word, in a good a note I had the Mrs. Gisburn's resolve had been taken. Gisburn had been his painting; and Mrs. Gisburn--it was rich on his eyes on the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_losses,label=\"train\")\n",
        "plt.plot(val_losses,label=\"val\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "aevBwUTMtbZ-",
        "outputId": "dde653f8-b469-4b43-8e6c-2a3d09edd800"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"model.pth\")"
      ],
      "metadata": {
        "id": "CliqJDVZudZ_"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2=GPTModel(GPT_CONFIG_124M)\n",
        "model2.load_state_dict(torch.load(\"model.pth\"))\n",
        "model2.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xXPECVKW4yB",
        "outputId": "c2c9dabf-1f9d-4ac9-aa6d-06d10bb286d0"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (token_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(258, 768)\n",
              "  (tblocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"model_state_dict\":model.state_dict(),\n",
        "    \"optimizer_state_dict\":optimizer.state_dict(),\n",
        "\n",
        "},\"model_and_optimizer.pth\")"
      ],
      "metadata": {
        "id": "AAVbkWDLYNMI"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2=GPTModel(GPT_CONFIG_124M)\n",
        "checkpoint=torch.load(\"model_and_optimizer.pth\")\n",
        "model2.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer=torch.optim.AdamW(model2.parameters(),lr=1e-4,weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n"
      ],
      "metadata": {
        "id": "_WWBmZmXYd_i"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:].to(model.token_emb.weight.device) # Move input to model device\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1).to(idx.device)  # Move idx_next to the same device as idx\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True).to(idx.device)  # Move idx_next to the same device as idx\n",
        "\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "gz9ID8f1eZ3-"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k=25,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMIDc9kiedRe",
        "outputId": "7e07f801-1408-414a-dd7c-89da3113f9a8"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you remember getting who had his own a vill all what with Mrs. Professional amusing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow>=2.15.0 tqdm>=4.66"
      ],
      "metadata": {
        "id": "wtV0PYt5erIw"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests  # Make sure requests is installed\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path)\n",
        "\n",
        "    ## We have reached here until now ---> we have downloaded the files on our local machine.\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "def download_file(url, destination):\n",
        "    try:\n",
        "        # Send a GET request to download the file, disabling SSL verification\n",
        "        response = requests.get(url, stream=True, verify=False)\n",
        "\n",
        "        # Get the total file size from headers, defaulting to 0 if not present\n",
        "        file_size = int(response.headers.get(\"content-length\", 0))\n",
        "\n",
        "        # Check if file exists and has the same size\n",
        "        if os.path.exists(destination):\n",
        "            file_size_local = os.path.getsize(destination)\n",
        "            if file_size == file_size_local:\n",
        "                print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                return\n",
        "\n",
        "        # Define the block size for reading the file\n",
        "        block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "        # Initialize the progress bar with total file size\n",
        "        progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
        "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
        "            # Open the destination file in binary write mode\n",
        "            with open(destination, \"wb\") as file:\n",
        "                # Iterate over the file data in chunks\n",
        "                for chunk in response.iter_content(block_size):\n",
        "                    progress_bar.update(len(chunk))  # Update progress bar\n",
        "                    file.write(chunk)  # Write the chunk to the file\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading the file: {e}\")\n",
        "        print(f\"Please check the URL: {url}\")\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params"
      ],
      "metadata": {
        "id": "FPsgEBfjjQSp"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "6E4ttcfeewir",
        "outputId": "0cedd8d9-c9a9-4bb1-a735-a7edd504c812"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gpt_download3'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-131-2243819354.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgpt_download3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_and_load_gpt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpt_download3'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ou0qPRcXe1Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZRtlvT6gqnqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BHwp9FSLLFWn"
      }
    }
  ]
}